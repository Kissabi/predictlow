# PredictLow

The "out of memory" phenomenon occurs when a machine learning model runs out of available memory during training. This usually happens when the data set is too large or when the model is too complex for the system's memory capacity. This is a common problem in almost all machine learning algorithms. To overcome this problem, you can reduce the size of the data set, but only in the training phase, the problem can still persist in the prediction phase, and this is where predictlow comes in, to allow you to predict large data sets without the out-of-memory problem occurring.

## Improvements ğŸ’¹

Making predictions on large data sets without suffering the out-of-memory problem


## Authors ğŸ‘¨ğŸ½â€ğŸ’»

- [Kayenga Campos](https://github.com/Kissabi)
- [Hailes MaurÃ­cio](https://github.com/Hailes24)


## Recommended skills ğŸ› 

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)


## Making a contribution âœŠğŸ½

Contributions are always welcome ğŸ¤—!

Visit [AOSC](https://github.com/Kissabi) to learn how to get started.

Please follow this project's [Code Of Conduuct](https://mentorship.aosc.social/#/?id=code-of-conductcoc)




## References

 - [Out of memory](https://en.m.wikipedia.org/wiki/Out_of_memory)
 - [pip](https://pypi.org/project/pip/)
